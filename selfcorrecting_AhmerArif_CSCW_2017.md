A Closer Look at the Self-Correcting Crowd:  Examining Corrections in Online Rumors
===================================================================================

Link: [pdf](https://faculty.washington.edu/kstarbi/Arif_Starbird_CorrectiveBehavior_CSCW2017.pdf)

Ahmer Arif, John J. Robinson, Stephanie A. Stanek, Elodie Fichet+, Paul Townsend, Zena Worku, Kate Starbird HCDE, Department of Communication+ University of Washington, Seattle WA, 98195 {ahmer, soco, fjchou, stanek14, efichet, pjt33, zenaget, kstarbi}@uw.edu

This paper examines how users of social media correct online rumors during crisis events.

### Novelty and current gap

Although previous research also look at this self-correcting behavior and this self-correcting crowd, they mostly concentrated on leveraging these traces to detect online rumors. Consequently, very few studies have moved past the analysis of digital traces to interact directly with the users who were responsible for creating them.

Because there exists this important gap in the literature when it comes to develop a deeper understanding of how members of the crowd choose to correct online rumors, and different strategies they use to do this work, this paper tried to address it by examining two false rumors propagated in two different crisis events through combined analysis of trace data and interviews with 15 individuals that exhibited different behavior patterns of affrming, denying, and deleting actions of tweets related to the rumor.

### Background part

The flow of the background and related work part is like the following:

It first introduced that social media use is popular during crisis events, which has been described to have a great deal of favorable outcomes. However, it brings new challenges, which is the spread of rumors and misinformation.

Then it presents an overview of the dangerous potential of online rumors, and draws connection to social psychologists' research on the dynamics of rumor back into 1940s. The classic social psychology research has revealed important factors that act as drivers for the development and spread of rumors, such as information uncertainty and ambiguity along with individuals' anxiety about impacts and potential responses. Rumoring is not inherently a bad activity. The majority of people experiencing disasters are pro-social and active, some rumor participants in this context are motivated by the potential of helping others.

It then moves forward to the description of the state-of-the-art research on this topic. Previous research also noticed this "self-correcting" crowd. Mendoza et al. discovered that rumors tended to be questioned or challenged more by the crowd than factual reports. Their work concludes with a hypothesis that rumors could be automatically detected by algorithms using a content-based approach that identifies questioning or challenging tweets. Much of the research work that leverage the self-correcting behaviors of the crowd only analyze the traces to help detect the rumor, while few studies explore how members of the crowd choose to (or not to) correct online rumors, or the different strategies they use to to this work.


### Methodology

They took a mixed-method approach. First they conducted content-analysis on a set of tweet traces related to two crisis events. They manually classified each unique tweet as to whether it affirms or denies the rumor. Following this, they generated a behavior pattern or 'signature' for each ~user~. They use it to identify individuals that demonstrate different patterns of corrective behavior and used that to select interviewee candidates.

They drew from two distinct rumors/events not to draw sharp comparisons, but to identify convergent themes across rumor participants.
